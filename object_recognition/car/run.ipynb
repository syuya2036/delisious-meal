{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "^Cceiving objects:  23% (3694/16057)\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_10.jpg: 384x640 1 car, 304.9ms\n",
      "image 2/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_11.jpg: 384x640 1 car, 1 bus, 294.5ms\n",
      "image 3/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_12.jpg: 384x640 2 persons, 1 bus, 1 train, 283.1ms\n",
      "image 4/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_13.jpg: 384x640 1 bus, 284.1ms\n",
      "image 5/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_6.jpg: 384x640 1 car, 280.4ms\n",
      "image 6/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_7.jpg: 384x640 1 person, 1 car, 284.9ms\n",
      "image 7/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_8.jpg: 384x640 1 car, 1 truck, 300.0ms\n",
      "image 8/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_9.jpg: 384x640 1 car, 1 truck, 284.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'cup', 'person', 'bus', 'person', 'person', 'person', 'car', 'person', 'truck', 'person', 'tie', 'person', 'suitcase', 'car', 'backpack', 'cell phone', 'person', 'car', 'person', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'truck', 'person', 'car', 'person', 'train', 'car', 'car', 'toilet', 'car', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck']\n"
     ]
    }
   ],
   "source": [
    "from yolov5 import detect\n",
    "from ... import remote\n",
    "import requests\n",
    "\n",
    "def send_line_notify(notification_message):\n",
    "    \"\"\"\n",
    "    LINE„Å´ÈÄöÁü•„Åô„Çã\n",
    "    \"\"\"\n",
    "    line_notify_token = '7TxyBqWZmwLi2ue04PnPFYxSpPQQ9zsEeErZzYqIeka'\n",
    "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
    "    headers = {'Authorization': f'Bearer {line_notify_token}'}\n",
    "    data = {'message': f'message: {notification_message}'}\n",
    "    requests.post(line_notify_api, headers = headers, data = data)\n",
    "\n",
    "\n",
    "\n",
    "labels = detect.run(source=\"inference/images/\")\n",
    "print(labels)\n",
    "if \"person\" in labels:\n",
    "    send_line_notify(\"‰∫∫„ÅÑ„Åü„Çè\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    remote.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # ÂãïÁîª„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # „Éï„É¨„Éº„É†„É¨„Éº„Éà„ÇíÂèñÂæó\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Âá∫Âäõ„Éï„Ç©„É´„ÉÄ„Åå„Å™„Åë„Çå„Å∞‰ΩúÊàê\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    second_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # „Éï„É¨„Éº„É†„ÅåË™≠„ÅøËæº„ÇÅ„Å™„Åã„Å£„Åü„ÇâÁµÇ‰∫Ü\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # ÊØéÁßí„ÅÆÊúÄÂàù„ÅÆ„Éï„É¨„Éº„É†„Çí‰øùÂ≠ò\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{second_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            second_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# ‰ΩøÁî®‰æã\n",
    "extract_frames('./a.mp4', 'output_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7f42bc4620f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../car/yolov5/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yolov5s'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or yolov5m, yolov5l, yolov5x, custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'github'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         repo_or_dir = _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \"load\",\n\u001b[0m\u001b[1;32m    556\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36m_get_cache_or_reload\u001b[0;34m(github, force_reload, trust_repo, calling_fn, verbose, skip_validation)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# Parse github repo information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mrepo_owner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_repo_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;31m# Github allows branch name with slash '/',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# this causes confusion with path on both Linux and Windows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36m_parse_repo_info\u001b[0;34m(github)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mrepo_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgithub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mrepo_owner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('../car/yolov5/', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "# Images\n",
    "img = '../../‰∫∫„ÅÑ„Çã/image016.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "print(results.pandas().xyxy[0])\n",
    "\n",
    "#          xmin        ymin         xmax        ymax  confidence  class    name\n",
    "# 0  749.628357   43.006287  1148.310059  708.739563    0.876501      0  person\n",
    "# 1  433.496307  433.949493   517.907959  715.133179    0.658130     27     tie\n",
    "# 2  113.315979  196.360046  1093.051270  710.308228    0.596343      0  person\n",
    "# 3  986.139587  304.344147  1027.974243  420.158539    0.285012     27     tie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
