{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "^Cceiving objects:  23% (3694/16057)\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_10.jpg: 384x640 1 car, 304.9ms\n",
      "image 2/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_11.jpg: 384x640 1 car, 1 bus, 294.5ms\n",
      "image 3/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_12.jpg: 384x640 2 persons, 1 bus, 1 train, 283.1ms\n",
      "image 4/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_13.jpg: 384x640 1 bus, 284.1ms\n",
      "image 5/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_6.jpg: 384x640 1 car, 280.4ms\n",
      "image 6/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_7.jpg: 384x640 1 person, 1 car, 284.9ms\n",
      "image 7/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_8.jpg: 384x640 1 car, 1 truck, 300.0ms\n",
      "image 8/8 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_9.jpg: 384x640 1 car, 1 truck, 284.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'cup', 'person', 'bus', 'person', 'person', 'person', 'car', 'person', 'truck', 'person', 'tie', 'person', 'suitcase', 'car', 'backpack', 'cell phone', 'person', 'car', 'person', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'truck', 'person', 'car', 'person', 'train', 'car', 'car', 'toilet', 'car', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck']\n"
     ]
    }
   ],
   "source": [
    "from yolov5 import detect\n",
    "from ... import remote\n",
    "import requests\n",
    "\n",
    "def send_line_notify(notification_message):\n",
    "    \"\"\"\n",
    "    LINEã«é€šçŸ¥ã™ã‚‹\n",
    "    \"\"\"\n",
    "    line_notify_token = '7TxyBqWZmwLi2ue04PnPFYxSpPQQ9zsEeErZzYqIeka'\n",
    "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
    "    headers = {'Authorization': f'Bearer {line_notify_token}'}\n",
    "    data = {'message': f'message: {notification_message}'}\n",
    "    requests.post(line_notify_api, headers = headers, data = data)\n",
    "\n",
    "\n",
    "\n",
    "labels = detect.run(source=\"inference/images/\")\n",
    "print(labels)\n",
    "if \"person\" in labels:\n",
    "    send_line_notify(\"äººã„ãŸã‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    remote.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    second_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒèª­ã¿è¾¼ã‚ãªã‹ã£ãŸã‚‰çµ‚äº†\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # æ¯ç§’ã®æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{second_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            second_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "extract_frames('./a.mp4', 'output_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
