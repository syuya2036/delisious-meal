{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "^Cceiving objects:  23% (3694/16057)\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/koyo/git/delicious_meal/object_recognition/car/yolov5\n"
     ]
    }
   ],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=inference/images/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/1 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/bus.jpg: 640x480 4 persons, 1 bus, 395.6ms\n",
      "Speed: 1.4ms pre-process, 395.6ms inference, 3.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source inference/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_line_notify(notification_message):\n",
    "    \"\"\"\n",
    "    LINE„Å´ÈÄöÁü•„Åô„Çã\n",
    "    \"\"\"\n",
    "    line_notify_token = '7TxyBqWZmwLi2ue04PnPFYxSpPQQ9zsEeErZzYqIeka'\n",
    "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
    "    headers = {'Authorization': f'Bearer {line_notify_token}'}\n",
    "    data = {'message': f'message: {notification_message}'}\n",
    "    requests.post(line_notify_api, headers = headers, data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_10.jpg: 384x640 1 car, 305.4ms\n",
      "image 2/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_11.jpg: 384x640 1 car, 1 bus, 287.4ms\n",
      "image 3/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_12.jpg: 384x640 2 persons, 1 bus, 1 train, 285.2ms\n",
      "image 4/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_13.jpg: 384x640 1 bus, 282.9ms\n",
      "image 5/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_14.jpg: 384x640 1 person, 278.9ms\n",
      "image 6/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_15.jpg: 384x640 1 person, 296.8ms\n",
      "image 7/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_6.jpg: 384x640 1 car, 295.6ms\n",
      "image 8/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_7.jpg: 384x640 1 person, 1 car, 292.1ms\n",
      "image 9/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_8.jpg: 384x640 1 car, 1 truck, 286.1ms\n",
      "image 10/10 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/frame_9.jpg: 384x640 1 car, 1 truck, 286.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'cup', 'person', 'bus', 'person', 'person', 'person', 'car', 'person', 'truck', 'person', 'tie', 'person', 'suitcase', 'car', 'backpack', 'cell phone', 'person', 'car', 'person', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'truck', 'person', 'car', 'person', 'train', 'car', 'car', 'toilet', 'car', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck', 'car', 'car', 'bus', 'person', 'train', 'bus', 'person', 'bus', 'person', 'person', 'car', 'car', 'person', 'car', 'truck', 'car', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import detect\n",
    "\n",
    "labels = detect.run(source=\"inference/images/\")\n",
    "print(labels)\n",
    "if \"person\" in labels:\n",
    "    send_line_notify(\"‰∫∫„ÅÑ„Åü„Çè\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # ÂãïÁîª„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # „Éï„É¨„Éº„É†„É¨„Éº„Éà„ÇíÂèñÂæó\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Âá∫Âäõ„Éï„Ç©„É´„ÉÄ„Åå„Å™„Åë„Çå„Å∞‰ΩúÊàê\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    second_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # „Éï„É¨„Éº„É†„ÅåË™≠„ÅøËæº„ÇÅ„Å™„Åã„Å£„Åü„ÇâÁµÇ‰∫Ü\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # ÊØéÁßí„ÅÆÊúÄÂàù„ÅÆ„Éï„É¨„Éº„É†„Çí‰øùÂ≠ò\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{second_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            second_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# ‰ΩøÁî®‰æã\n",
    "extract_frames('./a.mp4', 'output_frames')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
