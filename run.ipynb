{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "^Cceiving objects:  23% (3694/16057)\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/koyo/git/delicious_meal/object_recognition/car/yolov5\n"
     ]
    }
   ],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=inference/images/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/1 /Users/koyo/git/delicious_meal/object_recognition/car/yolov5/inference/images/bus.jpg: 640x480 4 persons, 1 bus, 395.6ms\n",
      "Speed: 1.4ms pre-process, 395.6ms inference, 3.1ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source inference/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_line_notify(notification_message):\n",
    "    \"\"\"\n",
    "    LINEに通知する\n",
    "    \"\"\"\n",
    "    line_notify_token = '7TxyBqWZmwLi2ue04PnPFYxSpPQQ9zsEeErZzYqIeka'\n",
    "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
    "    headers = {'Authorization': f'Bearer {line_notify_token}'}\n",
    "    data = {'message': f'message: {notification_message}'}\n",
    "    requests.post(line_notify_api, headers = headers, data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-acc769d6d036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference/images/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"person\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/delicious_meal/detect.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_one_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectMultiBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMG_FORMATS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVID_FORMATS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoadImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoadScreenshots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoadStreams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import detect\n",
    "\n",
    "labels = detect.run(source=\"inference/images/\")\n",
    "print(labels)\n",
    "if \"person\" in labels:\n",
    "    send_line_notify(\"人いたわ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # 動画ファイルを読み込む\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # フレームレートを取得\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # 出力フォルダがなければ作成\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    second_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # フレームが読み込めなかったら終了\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 毎秒の最初のフレームを保存\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{second_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            second_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# 使用例\n",
    "extract_frames('./a.mp4', 'output_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 63\n",
      "FP: 2\n",
      "FN: 32\n",
      "TN: 23\n",
      "accuracy: 0.7166666666666667\n",
      "sensitivity: 0.6631578947368421\n",
      "specificity: 0.92\n",
      "precision: 0.9692307692307692\n",
      "f_score: 0.7875\n"
     ]
    }
   ],
   "source": [
    "# 混同行列の値\n",
    "TP = 63 # 予測が「人いる」、実際も「人いる」\n",
    "FP = 2 # 予測が「人いる」、実際は「人いない」\n",
    "FN = 32 # 予測が「人いない」、実際は「人いる」\n",
    "TN = 23 # 予測が「人いない」、実際も「人いない」\n",
    "\n",
    "# 各指標の計算\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"sensitivity:\", sensitivity)\n",
    "print(\"specificity:\", specificity)\n",
    "print(\"precision:\", precision)\n",
    "print(\"f_score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 66\n",
      "FP: 2\n",
      "FN: 16\n",
      "TN: 22\n",
      "accuracy: 0.8301886792452831\n",
      "sensitivity: 0.8048780487804879\n",
      "specificity: 0.9166666666666666\n",
      "precision: 0.9705882352941176\n",
      "f_score: 0.8800000000000001\n"
     ]
    }
   ],
   "source": [
    "# 混同行列の値\n",
    "TP = 66 # 予測が「人いる」、実際も「人いる」\n",
    "FP = 2 # 予測が「人いる」、実際は「人いない」\n",
    "FN = 16 # 予測が「人いない」、実際は「人いる」\n",
    "TN = 22 # 予測が「人いない」、実際も「人いない」\n",
    "\n",
    "# 各指標の計算\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"sensitivity:\", sensitivity)\n",
    "print(\"specificity:\", specificity)\n",
    "print(\"precision:\", precision)\n",
    "print(\"f_score:\", f_score)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
