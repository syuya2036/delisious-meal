{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd object_recognition/car/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "^Cceiving objects:  23% (3694/16057)\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -f detect.py object_recognition/car/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=object_recognition/car/yolov5/yolov5s.pt, source=/Users/koyo/git/delicious_meal/inai, data=object_recognition/car/yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=object_recognition/car/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-227-ge4df1ec Python-3.8.8 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/31 /Users/koyo/git/delicious_meal/inai/image1.jpg: 448x640 (no detections), 375.9ms\n",
      "0\n",
      "image 2/31 /Users/koyo/git/delicious_meal/inai/image10.jpg: 384x640 (no detections), 305.6ms\n",
      "0\n",
      "image 3/31 /Users/koyo/git/delicious_meal/inai/image11.jpg: 384x640 (no detections), 285.7ms\n",
      "0\n",
      "image 4/31 /Users/koyo/git/delicious_meal/inai/image12.jpg: 384x640 (no detections), 282.8ms\n",
      "0\n",
      "image 5/31 /Users/koyo/git/delicious_meal/inai/image13.jpg: 384x640 (no detections), 280.6ms\n",
      "0\n",
      "image 6/31 /Users/koyo/git/delicious_meal/inai/image14.jpg: 384x640 (no detections), 278.6ms\n",
      "0\n",
      "image 7/31 /Users/koyo/git/delicious_meal/inai/image15.jpg: 384x640 (no detections), 291.1ms\n",
      "0\n",
      "image 8/31 /Users/koyo/git/delicious_meal/inai/image16.jpg: 384x640 (no detections), 280.6ms\n",
      "0\n",
      "image 9/31 /Users/koyo/git/delicious_meal/inai/image17.jpg: 384x640 1 person, 290.9ms\n",
      "1\n",
      "image 10/31 /Users/koyo/git/delicious_meal/inai/image18.jpg: 384x640 (no detections), 287.6ms\n",
      "1\n",
      "image 11/31 /Users/koyo/git/delicious_meal/inai/image19.jpg: 384x640 (no detections), 281.3ms\n",
      "1\n",
      "image 12/31 /Users/koyo/git/delicious_meal/inai/image2.jpg: 480x640 (no detections), 367.0ms\n",
      "1\n",
      "image 13/31 /Users/koyo/git/delicious_meal/inai/image20.jpg: 384x640 (no detections), 284.2ms\n",
      "1\n",
      "image 14/31 /Users/koyo/git/delicious_meal/inai/image21.jpg: 384x640 (no detections), 277.7ms\n",
      "1\n",
      "image 15/31 /Users/koyo/git/delicious_meal/inai/image22.jpg: 384x640 (no detections), 284.7ms\n",
      "1\n",
      "image 16/31 /Users/koyo/git/delicious_meal/inai/image23.jpg: 384x640 (no detections), 289.9ms\n",
      "1\n",
      "image 17/31 /Users/koyo/git/delicious_meal/inai/image24.jpg: 384x640 1 person, 288.2ms\n",
      "2\n",
      "image 18/31 /Users/koyo/git/delicious_meal/inai/image25.jpg: 384x640 (no detections), 282.0ms\n",
      "2\n",
      "image 19/31 /Users/koyo/git/delicious_meal/inai/image26.jpg: 384x640 (no detections), 285.0ms\n",
      "2\n",
      "image 20/31 /Users/koyo/git/delicious_meal/inai/image27.jpg: 384x640 (no detections), 286.5ms\n",
      "2\n",
      "image 21/31 /Users/koyo/git/delicious_meal/inai/image28.jpg: 384x640 (no detections), 301.1ms\n",
      "2\n",
      "image 22/31 /Users/koyo/git/delicious_meal/inai/image29.jpg: 384x640 (no detections), 297.9ms\n",
      "2\n",
      "image 23/31 /Users/koyo/git/delicious_meal/inai/image3.jpg: 448x640 (no detections), 344.7ms\n",
      "2\n",
      "image 24/31 /Users/koyo/git/delicious_meal/inai/image30.jpg: 384x640 (no detections), 297.1ms\n",
      "2\n",
      "image 25/31 /Users/koyo/git/delicious_meal/inai/image31.jpg: 480x640 (no detections), 355.0ms\n",
      "2\n",
      "image 26/31 /Users/koyo/git/delicious_meal/inai/image4.jpg.webp: 224x640 (no detections), 198.9ms\n",
      "2\n",
      "image 27/31 /Users/koyo/git/delicious_meal/inai/image5.jpg: 448x640 (no detections), 326.9ms\n",
      "2\n",
      "image 28/31 /Users/koyo/git/delicious_meal/inai/image6.jpg: 416x640 (no detections), 320.9ms\n",
      "2\n",
      "image 29/31 /Users/koyo/git/delicious_meal/inai/image7.jpg: 480x640 (no detections), 344.2ms\n",
      "2\n",
      "image 30/31 /Users/koyo/git/delicious_meal/inai/image8.jpg: 320x640 (no detections), 253.3ms\n",
      "2\n",
      "image 31/31 /Users/koyo/git/delicious_meal/inai/image9.jpg: 384x640 (no detections), 278.4ms\n",
      "2\n",
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with fsevents reloader\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 158-073-177\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"object_recognition/car/yolov5/detect.py\", line 322, in <module>\n",
      "    subprocess.run([\"python\", \"./webapp/app.py\"])\n",
      "  File \"/Users/koyo/opt/anaconda3/lib/python3.8/subprocess.py\", line 495, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/Users/koyo/opt/anaconda3/lib/python3.8/subprocess.py\", line 1020, in communicate\n",
      "    self.wait()\n",
      "  File \"/Users/koyo/opt/anaconda3/lib/python3.8/subprocess.py\", line 1083, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "  File \"/Users/koyo/opt/anaconda3/lib/python3.8/subprocess.py\", line 1808, in _wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/Users/koyo/opt/anaconda3/lib/python3.8/subprocess.py\", line 1766, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python object_recognition/car/yolov5/detect.py --source /Users/koyo/git/delicious_meal/inai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # 動画ファイルを読み込む\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # フレームレートを取得\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # 出力フォルダがなければ作成\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    second_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # フレームが読み込めなかったら終了\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 毎秒の最初のフレームを保存\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_path = os.path.join(output_folder, f\"frame_{second_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            second_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# 使用例\n",
    "extract_frames('./a.mp4', 'output_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 63\n",
      "FP: 2\n",
      "FN: 32\n",
      "TN: 23\n",
      "accuracy: 0.7166666666666667\n",
      "sensitivity: 0.6631578947368421\n",
      "specificity: 0.92\n",
      "precision: 0.9692307692307692\n",
      "f_score: 0.7875\n"
     ]
    }
   ],
   "source": [
    "# 混同行列の値\n",
    "TP = 63 # 予測が「人いる」、実際も「人いる」\n",
    "FP = 2 # 予測が「人いる」、実際は「人いない」\n",
    "FN = 32 # 予測が「人いない」、実際は「人いる」\n",
    "TN = 23 # 予測が「人いない」、実際も「人いない」\n",
    "\n",
    "# 各指標の計算\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"sensitivity:\", sensitivity)\n",
    "print(\"specificity:\", specificity)\n",
    "print(\"precision:\", precision)\n",
    "print(\"f_score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 76\n",
      "FP: 2\n",
      "FN: 18\n",
      "TN: 29\n",
      "accuracy: 0.84\n",
      "sensitivity: 0.8085106382978723\n",
      "specificity: 0.9354838709677419\n",
      "precision: 0.9743589743589743\n",
      "f_score: 0.8837209302325582\n"
     ]
    }
   ],
   "source": [
    "# 混同行列の値\n",
    "TP = 76 # 予測が「人いる」、実際も「人いる」\n",
    "FP = 2 # 予測が「人いる」、実際は「人いない」\n",
    "FN = 18 # 予測が「人いない」、実際は「人いる」\n",
    "TN = 29 # 予測が「人いない」、実際も「人いない」\n",
    "\n",
    "# 各指標の計算\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"sensitivity:\", sensitivity)\n",
    "print(\"specificity:\", specificity)\n",
    "print(\"precision:\", precision)\n",
    "print(\"f_score:\", f_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
